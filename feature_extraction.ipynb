{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extraction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattfredericksen/CSCE-4205-ML-Project/blob/dataShrinkage/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoPyrrXci7Bd"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rLWSn9cG4sf",
        "outputId": "e2e15b3c-8582-4f56-b557-330d94677bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from time import time\n",
        "from contextlib import suppress\n",
        "\n",
        "import gzip\n",
        "from urllib.request import urlopen\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHnx1JGh93ls"
      },
      "source": [
        "# Progress Bar\n",
        "# https://colab.research.google.com/drive/1I2o3Ie34vJ3G4M6eE54-OyrmzJNBwhOp#scrollTo=EbF9oPhzOqZj\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(f\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 50%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SKxbcgAHdnv"
      },
      "source": [
        "**Dataset links**\n",
        "- [Books (\\~30 million, too large!)](http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Books_5.json.gz)  \n",
        "- [Clothing, Shoes, and Jewelry (\\~11 million)](http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Clothing_Shoes_and_Jewelry_5.json.gz)    \n",
        "- [Electronics (\\~7 million)](http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Electronics_5.json.gz  )  \n",
        "- [Home and Kitchen (\\~7 million)](http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Home_and_Kitchen_5.json.gz)  \n",
        "- [Movies and TV (\\~3.5 million)](http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Movies_and_TV_5.json.gz)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3TZa1CtEzo0",
        "outputId": "4704013b-8cc0-4495-ee3e-fa952b02bcfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Movies_and_TV_5.json.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-15 01:47:05--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Movies_and_TV_5.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 791322468 (755M) [application/octet-stream]\n",
            "Saving to: ‘Movies_and_TV_5.json.gz’\n",
            "\n",
            "Movies_and_TV_5.jso 100%[===================>] 754.66M  18.5MB/s    in 42s     \n",
            "\n",
            "2020-11-15 01:47:48 (18.0 MB/s) - ‘Movies_and_TV_5.json.gz’ saved [791322468/791322468]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmoClcgGYYrY"
      },
      "source": [
        "# Feature Engineering\n",
        "**List of features**  \n",
        "`reviewerID` - ID of the reviewer, e.g. A2SUAM1J3GNN3B  \n",
        "`asin` - ID of the product, e.g. 0000013714  \n",
        "`reviewerName` - name of the reviewer  \n",
        "`vote` - helpful votes of the review  \n",
        "`style` - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"  \n",
        "`reviewText` - text of the review  \n",
        "`overall` - rating of the product  \n",
        "`summary` - summary of the review  \n",
        "`unixReviewTime` - time of the review (unix time)  \n",
        "`reviewTime` - time of the review (raw)  \n",
        "`image` - images that users post after they have received the product  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "milsWnjMJlzB",
        "outputId": "89859b26-0c17-42b6-d3b3-fe7f27abe4cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def drop_features(d):\n",
        "  kept_features = (\"overall\", \"reviewText\")\n",
        "  return {f: d[f] for f in kept_features}\n",
        "\n",
        "data = []\n",
        "\n",
        "with gzip.open(\"Movies_and_TV_5.json.gz\") as file:\n",
        "  for line in file:\n",
        "    with suppress(KeyError):\n",
        "      data.append(drop_features(json.loads(line.strip())))\n",
        "\n",
        "print(f'{len(data)} reviews loaded.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3408438 reviews loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AIC8juiM-9Y",
        "outputId": "009b9ffc-57b9-4afe-cc94-0cc4e1bd4c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "review_data = pd.DataFrame.from_dict(data)\n",
        "review_len = len(data)\n",
        "# del data\n",
        "review_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>So sorry I didn't purchase this years ago when...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Believe me when I tell you that you will recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I have seen X live many times, both in the ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I was so excited for this!  Finally, a live co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>X is one of the best punk bands ever. I don't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408433</th>\n",
              "      <td>4.0</td>\n",
              "      <td>The singing parts are very good as expected fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408434</th>\n",
              "      <td>5.0</td>\n",
              "      <td>This recording of the 2015 production by the M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408435</th>\n",
              "      <td>4.0</td>\n",
              "      <td>I do not wish to write a review about this rel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408436</th>\n",
              "      <td>5.0</td>\n",
              "      <td>It was a gift.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408437</th>\n",
              "      <td>4.0</td>\n",
              "      <td>This Otello originates from the Salzburg Festi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3408438 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         overall                                         reviewText\n",
              "0            5.0  So sorry I didn't purchase this years ago when...\n",
              "1            5.0  Believe me when I tell you that you will recei...\n",
              "2            5.0  I have seen X live many times, both in the ear...\n",
              "3            5.0  I was so excited for this!  Finally, a live co...\n",
              "4            5.0  X is one of the best punk bands ever. I don't ...\n",
              "...          ...                                                ...\n",
              "3408433      4.0  The singing parts are very good as expected fr...\n",
              "3408434      5.0  This recording of the 2015 production by the M...\n",
              "3408435      4.0  I do not wish to write a review about this rel...\n",
              "3408436      5.0                                     It was a gift.\n",
              "3408437      4.0  This Otello originates from the Salzburg Festi...\n",
              "\n",
              "[3408438 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4eGnUccPHTk"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n86vDEG7m0zL"
      },
      "source": [
        "class LemmaTokenizer:\n",
        "    def __init__(self, pb):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "        self.word_re = re.compile(r'[^A-Za-z]+')\n",
        "        # cut back sequences of the same character to at most 2\n",
        "        self.shorten_re = re.compile(r'(.)\\1{2,}')\n",
        "        self.call_count = 0\n",
        "        self.pb = pb\n",
        "        # experimental\n",
        "        self.stopwords = set(stopwords.words('english'))\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        self.call_count += 1\n",
        "        if self.call_count % 1024 == 0:\n",
        "            self.pb.update(progress(self.call_count, cut_len))\n",
        "        return tuple(self.wnl.lemmatize(self.shorten_re.sub(r'\\1\\1', t)) for t in self.word_re.split(doc) if t not in self.stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWet8MS8lI2M",
        "outputId": "8f3dfba2-1f35-4434-ab76-ba66853f8188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "cut_data = review_data[:review_len//10]\n",
        "cut_len = len(cut_data)\n",
        "cut_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>So sorry I didn't purchase this years ago when...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Believe me when I tell you that you will recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I have seen X live many times, both in the ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I was so excited for this!  Finally, a live co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>X is one of the best punk bands ever. I don't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340838</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Need a kid friendly movie with lots of laughs ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340839</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Pretty good though improbable plot.\\nGood acti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340840</th>\n",
              "      <td>5.0</td>\n",
              "      <td>great movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340841</th>\n",
              "      <td>5.0</td>\n",
              "      <td>10 stars......You will love it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340842</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Really enjoyed it!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>340843 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        overall                                         reviewText\n",
              "0           5.0  So sorry I didn't purchase this years ago when...\n",
              "1           5.0  Believe me when I tell you that you will recei...\n",
              "2           5.0  I have seen X live many times, both in the ear...\n",
              "3           5.0  I was so excited for this!  Finally, a live co...\n",
              "4           5.0  X is one of the best punk bands ever. I don't ...\n",
              "...         ...                                                ...\n",
              "340838      5.0  Need a kid friendly movie with lots of laughs ...\n",
              "340839      4.0  Pretty good though improbable plot.\\nGood acti...\n",
              "340840      5.0                                        great movie\n",
              "340841      5.0                     10 stars......You will love it\n",
              "340842      5.0                                 Really enjoyed it!\n",
              "\n",
              "[340843 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILy3aqlnHbuT",
        "outputId": "50b2c9e9-0bbd-4de6-80a1-468b8f567515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "start = time()\n",
        "vectorizer.fit_transform(cut_data['reviewText'])\n",
        "print(f'execution time: {((time() - start) / 60):.1f} minutes')\n",
        "print(f'{len(vectorizer.get_feature_names())} features (unique words)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execution time: 0.4 minutes\n",
            "179115 features (unique words)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFvSHYiVrL4i",
        "outputId": "bbc8dcc1-195d-4c82-9339-dc0c986cc720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "pb = display(progress(0, cut_len), display_id=True)\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=LemmaTokenizer(pb))\n",
        "start = time()\n",
        "# temporarily cutting back review_len\n",
        "vectorizer.fit_transform(cut_data['reviewText'])\n",
        "print(f'execution time: {((time() - start) / 60):.1f} minutes')\n",
        "print(f'{len(vectorizer.get_feature_names())} features (unique words)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='340992'\n",
              "            max='340843',\n",
              "            style='width: 50%'\n",
              "        >\n",
              "            340992\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['le', 'u'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "execution time: 2.2 minutes\n",
            "157822 features (unique words)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J4_LtRMEqHx",
        "outputId": "c89d84b8-a982-4e6e-d707-738dab2789a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vectorizer.get_feature_names()[:50])\n",
        "print(vectorizer.get_feature_names()[10000:10050])\n",
        "print(vectorizer.get_feature_names()[157800:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', 'aa', 'aabcu', 'aaberg', 'aac', 'aacckk', 'aaceptional', 'aack', 'aackk', 'aacs', 'aacute', 'aadams', 'aadditional', 'aado', 'aadoores', 'aae', 'aaf', 'aafes', 'aagean', 'aagghh', 'aagh', 'aah', 'aahed', 'aahh', 'aahhaahaa', 'aahhaahh', 'aahhing', 'aahing', 'aahoo', 'aahs', 'aaiirr', 'aainst', 'aak', 'aakafranz', 'aaker', 'aakroyd', 'aalbaek', 'aalberg', 'aaliyah', 'aall', 'aalong', 'aalready', 'aalto', 'aamateur', 'aamazing', 'aamazon', 'aamerican', 'aames', 'aamfbca', 'aamuuzzon']\n",
            "['backprojected', 'backprojection', 'backprojections', 'backprop', 'backrgound', 'backroad', 'backroads', 'backroom', 'backround', 'backrounds', 'backrub', 'backrupt', 'backscapes', 'backscratcher', 'backscreen', 'backseat', 'backseated', 'backshooting', 'backside', 'backsight', 'backslapping', 'backslaps', 'backslid', 'backslide', 'backsliding', 'backson', 'backstab', 'backstabbed', 'backstabber', 'backstabbers', 'backstabbing', 'backstabbling', 'backstabs', 'backstage', 'backstein', 'backsteps', 'backstop', 'backstories', 'backstory', 'backstoryless', 'backstreet', 'backstreets', 'backstroke', 'backt', 'backtalk', 'backtrack', 'backtracked', 'backtracking', 'backtracks', 'backula']\n",
            "['zygon', 'zygons', 'zygote', 'zygrot', 'zyifi', 'zyklnb', 'zyklon', 'zyl', 'zylberstein', 'zylberstien', 'zyra', 'zyran', 'zys', 'zysklu', 'zyton', 'zyu', 'zyxy', 'zyyvaqos', 'zz', 'zze', 'zztop', 'zzupergirl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yd6ZKeeBEZp"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixroIsHHiIay"
      },
      "source": [
        "# Training/Testing Split\n",
        "In the next cell, we randomly split the data into training and testing sets. At a later time, we may want switch to using [stratified K-fold cross validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold), which performs cross validation while ensuring an equal distribution of classes (star ratings)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPQK9EiSchya"
      },
      "source": [
        "targets = review_data[['overall']]\n",
        "features = review_data[['reviewText']]\n",
        "train_features, test_features, train_targets, test_targets = train_test_split(features, targets, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPinOM4QV7rT"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes"
      ]
    }
  ]
}